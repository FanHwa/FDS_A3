AAA_2013J_df <- AAA_2013J_df %>%
mutate(score_range = case_when(
score >= 0 & score < 60 ~ "[0, 60)",
score >= 60 & score < 70 ~ "[60, 70)",
score >= 70 & score < 80 ~ "[70, 80)",
score >= 80 & score <= 100 ~ "[80, 100]"
))
# Print the first 5 rows of the data with the new "score_range" column
print(head(AAA_2013J_df %>% select(id_assessment, score, score_range), 5))
# Draw a chart to plot the number of students of different score_range for each id_assessment value
score_range_plot <- AAA_2013J_df %>%
group_by(id_assessment, score_range) %>%
summarise(count = n(), .groups = 'drop') %>%
ggplot(aes(x = id_assessment, y = count, fill = score_range)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Number of Students of Different Score Range for Each id_assessment",
x = "id_assessment",
y = "Number of Students",
fill = "Score Range") +
theme_minimal() +
scale_fill_brewer(palette = "Set1")
# Print the plot
print(score_range_plot)
# Check for NA values in the is_banked column
na_values_is_banked <- student_assessment %>%
summarise(is_banked_na = sum(is.na(is_banked)))
# Print the NA values in the is_banked column
print(na_values_is_banked)
# Filter out rows where the score column is not NA
student_assessment_removed_score_na <- student_assessment %>%
filter(!is.na(score))
# Plot a comparison of scores between banked and non-banked assessments
ggplot(student_assessment_removed_score_na, aes(x = as.factor(is_banked), y = score, fill = as.factor(is_banked))) +
geom_boxplot() +
labs(title = "Comparison of Scores: Banked vs Non-Banked Assessments",
x = "Is Banked",
y = "Score",
fill = "Is Banked") +
scale_fill_discrete(labels = c("No", "Yes")) +
theme_minimal()
# Merge the "assessment_type" column from assessments.csv into studentAssessment
student_assessment_with_type <- student_assessment %>%
inner_join(assessments %>% select(id_assessment, assessment_type), by = "id_assessment")
# Print the first 5 rows of the merged data
print(student_assessment_with_type %>% select(id_assessment, score, assessment_type))
# Investigate the relationship between the score, assessment_type, and is_banked
# Calculate the average score for each assessment type, is_banked combination
avg_scores_assessment_type <- student_assessment_with_type %>%
group_by(assessment_type, is_banked) %>%
summarise(avg_score = mean(score, na.rm = TRUE), count_students = n())
# Print summary of average scores for each assessment type, is_banked combination
print(avg_scores_assessment_type)
# Visualize the relationship between the score, assessment_type, and is_banked
ggplot(student_assessment_with_type, aes(x = assessment_type, y = score, fill = as.factor(is_banked))) +
geom_boxplot() +
labs(title = "Comparison of Scores: Assessment Type and Is Banked",
x = "Assessment Type",
y = "Score",
fill = "Is Banked") +
scale_fill_discrete(labels = c("No", "Yes")) +
theme_minimal()
# Calculate the frequency of each student in the dataset
student_frequency <- student_assessment %>%
count(id_student, name = "frequency") %>%
arrange(desc(frequency))
# Print the top 10 students with the highest frequency
print(head(student_frequency, 10))
# Filter out data of the top 3 students that appear most frequently in the dataset
top_3_students <- student_assessment %>%
filter(id_student %in% head(student_frequency$id_student, 3))
# Print the first 5 rows of the data for the top 3 students
print(top_3_students)
# Get some statistics of the 3 students' performance
performance_stats <- top_3_students %>%
group_by(id_student) %>%
summarise(
mean_score = mean(score, na.rm = TRUE),
min_score = min(score, na.rm = TRUE),
max_score = max(score, na.rm = TRUE)
)
# Print the performance statistics of the top 3 students
print(performance_stats)
# Analyze relationship between submission timing and performance
ggplot(top_3_students, aes(x = dates_since_submitted, y = score, color = factor(id_student))) +
geom_point() +
facet_wrap(~ id_student, ncol = 1) +
scale_color_manual(values = c("red", "blue", "black")) +
labs(title = "Submission Timing vs Performance",
x = "Days Since Submitted",
y = "Score",
color = "Student ID") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
# Increase the maximum number of characters printed per line
options(width = 200)
# Print data for inspection
print(student_info)
unique_region_raw_list <- student_info %>%
select(region) %>%
distinct() %>%
arrange(region) %>%
as.list()
# Print all unique values
print(unique_region_raw_list)
# Convert region names to lowercase
student_info <- student_info %>%
mutate(region = tolower(region))
# Remove underscores from region names
student_info <- student_info %>%
mutate(region = str_replace_all(region, "_", " "))
# Replace 'religion' with 'region' in region names
student_info <- student_info %>%
mutate(region = str_replace_all(region, "religion", "region"))
# Replace 'anglican' with 'anglian' in region names
student_info <- student_info %>%
mutate(region = str_replace_all(region, "anglican", "anglian"))
# Replace 'wales region' with 'wales' in region names
student_info <- student_info %>%
mutate(region = str_replace_all(region, "wales region", "wales"))
# Replace 'west midland region' with 'west midlands region' in region names
student_info <- student_info %>%
mutate(region = str_replace_all(region, "west midland region", "west midlands region"))
# Print all unique values after cleaning
unique_region_cleaned_list <- student_info %>%
select(region) %>%
distinct() %>%
arrange(region) %>%
as.list()
print(unique_region_cleaned_list)
# Filter rows with region name "lower than a level"
lower_than_a_level_df <- student_info %>%
filter(region == "lower than a level")
glimpse(lower_than_a_level_df)
# Replace the region name "lower than a level" with NA
student_info <- student_info %>%
mutate(region = ifelse(region == "lower than a level", NA, region))
# Check the unique values after replacing "lower than a level" with NA
unique_region_final_list <- student_info %>%
select(region) %>%
distinct() %>%
arrange(region) %>%
as.list()
print(unique_region_final_list)
# Count number of unique values after pre-processing, ignoring NA
unique_region_count <- student_info %>%
select(region) %>%
distinct() %>%
arrange(region) %>%
na.omit() %>%
nrow()
print(paste("Number of unique 'region' values:", unique_region_count))
# Print 1 example of feedback comments
print(student_info$feedback_from_student[1])
# Regular Expression pattern to extract overall score and feedback comment
pattern_overall_score <- "(?<=Overall Score: )\\d(?=/5)"
pattern_feedback_comment <- "(?<=\\n\").*(?=\")"
# Extract overall score
student_info <- student_info %>%
mutate(overall_score = as.numeric(str_extract(feedback_from_student, pattern_overall_score)))
# Extract feedback comment
student_info <- student_info %>%
mutate(feedback_comment = str_extract(feedback_from_student, pattern_feedback_comment))
# Use glimpse to view the data
glimpse(student_info %>% select(overall_score, feedback_comment))
# Filter rows that mention interacting or engaging in the feedback comment and provide an overall score of 1 or 2
feedback_filtered <- student_info %>%
filter(
(str_detect(feedback_comment, "interacting") | str_detect(feedback_comment, "engaging")) &
(overall_score == 1 | overall_score == 2)
)
# Use glimpse to view the data
glimpse(feedback_filtered %>% select(overall_score, feedback_comment))
# Count the number of student feedback comments that mention interacting or engaging and provide an overall score of 1 or 2
count_feedback <- nrow(feedback_filtered)
print(paste("Student feedback comments that mention interacting or engaging and provide an overall score of 1 or 2: ", (count_feedback)))
# Print the first 5 rows of the date column
print(head(student_info$feedback_received_date, 5))
pattern_remove_ordinal <- "(\\d{1,2})(st|nd|rd|th)"
# Clean the ordinal indicators and day names, and then parse the date
student_info <- student_info %>%
# Remove ordinal indicators (e.g., "2nd" becomes "2")
mutate(feedback_received_date_cleaned = str_replace_all(feedback_received_date, pattern_remove_ordinal, "\\1")) %>%
# Convert the cleaned string to a proper date format
mutate(feedback_date_formatted = dmy(feedback_received_date_cleaned))
# Print the first 5 rows of the feedback_received_date and feedback_date_formatted column
print(head(student_info %>% select(feedback_received_date, feedback_date_formatted), 5))
# Find the earliest and latest feedback dates
earliest_date <- min(student_info$feedback_date_formatted, na.rm = TRUE)
latest_date <- max(student_info$feedback_date_formatted, na.rm = TRUE)
print(paste("Earliest feedback date: ", earliest_date))
print(paste("Latest feedback date: ", latest_date))
# Check the unique values in the gender column
unique_genders <- unique(student_info$gender)
print("Unique values in the gender column:")
print(unique_genders)
# Filter out rows where gender is not NA
student_info_filtered <- student_info %>%
filter(!is.na(gender))
# Calculate the counts of students by gender for each code_module
gender_distribution <- student_info_filtered %>%
group_by(code_module, gender) %>%
summarise(count = n(), .groups = 'drop') %>%
# Reshape into wide format
pivot_wider(names_from = gender, values_from = count, values_fill = list(count = 0)) %>%
mutate(
total = M + F,           # Calculate total students
fraction_M = M / total,  # Calculate fraction of males
fraction_F = F / total   # Calculate fraction of females
)
# Print the formatted gender distribution table
print(gender_distribution)
# Reshape the data to long format for plotting
gender_distribution_long <- gender_distribution %>%
pivot_longer(cols = c(fraction_M, fraction_F),
names_to = "gender",
values_to = "fraction") %>%
mutate(gender = ifelse(gender == "fraction_M", "M", "F"))  # Rename fraction columns to "M" and "F"
# Visualize the fractions using a bar plot
ggplot(gender_distribution_long, aes(x = code_module, y = fraction, fill = gender)) +
geom_bar(stat = "identity", position = "fill") +
scale_y_continuous(labels = scales::percent) +
labs(title = "Gender Distribution by Module Code",
x = "Module",
y = "Fraction of Students",
fill = "Gender") +
theme_minimal()
# Calculate the total number of students for each region and highest education
temp <- student_info %>%
group_by(region, highest_education) %>%
summarise(total_students = n(), .groups = 'drop')
# Print the 'temp' dataset
print(temp)
# Drop rows with NA values in the highest_education column
temp <- temp %>%
filter(!is.na(highest_education))
# Print the 'temp' dataset after dropping NA values
print(temp)
tapply(temp$total_students, temp$highest_education, summary)
# Read the studentAssessment.csv file
student_assessment <- read_csv("studentAssessment.csv")
glimpse(student_assessment)
# Read the assessments.csv file
assessments <- read_csv("assessments.csv")
glimpse(assessments)
# Merge student info and student assessment data frames based on id_student
merged_student_df <- student_info %>%
inner_join(student_assessment, by = "id_student")
# Print the first 5 rows of the merged data
print(merged_student_df)
# Check for NA values in the overall_score and score columns
na_values <- merged_student_df %>%
summarise(
overall_score_na = sum(is.na(overall_score)),
score_na = sum(is.na(score))
)
# Print the NA values
print(na_values)
# Filter the data where the score column is not NA
score_not_na_df <- merged_student_df %>%
filter(!is.na(score))
# Check the range of overall_score and score columns
scores_range_values <- score_not_na_df %>%
summarise(
min_overall_score = min(overall_score),
max_overall_score = max(overall_score),
min_score = min(score),
max_score = max(score)
)
# Print the range values
print(scores_range_values)
# Calculate the correlation between the overall score and the score in studentAssessment.csv
correlation_score <- score_not_na_df %>%
summarise(correlation = cor(overall_score, score, use = "complete.obs"))
# Print the correlation
print(correlation_score)
# Visualize the relationship between feedback scores and assessment scores with improved colors and legend
ggplot(score_not_na_df, aes(x = overall_score, y = score)) +
geom_point(aes(color = "Points"), size = 2, alpha = 0.6) +  # Points with color and transparency
geom_smooth(aes(color = "Trend Line"), method = "lm", linewidth = 1.5) +  # Line with color and thicker size
labs(title = "Relationship between Feedback Scores and Assessment Scores",
x = "Feedback Score (Overall Score)",
y = "Score in studentAssessment.csv",
color = "Legend") +  # Add title for the legend
scale_color_manual(values = c("Points" = "darkorange", "Trend Line" = "blue")) +  # Custom colors
theme_minimal()
# Merge the "weight" column from assessments.csv into studentAssessment.csv
merged_student_df <- merged_student_df %>%
inner_join((assessments %>% select(id_assessment, weight)), by = "id_assessment")
# Print the id_assessment and weight columns
print(merged_student_df %>% select(id_assessment, weight))
# Check for NA values in the weight column
weight_na_df <- merged_student_df %>%
filter(is.na(weight))
# Print the data
print(weight_na_df %>% select(id_assessment, weight))
# Investigate the relationship between the student feedback scores and the assessment weight
# Calculate the mean weight for each overall score
relationship_assessment_weight <- merged_student_df %>%
group_by(overall_score) %>%
summarise(mean_weight = mean(weight, na.rm = TRUE))
# Print the relationship between the student feedback scores and the assessment weight
print(relationship_assessment_weight)
ggplot(relationship_assessment_weight, aes(x = overall_score, y = mean_weight)) +
geom_point(aes(color = "Weight"), size = 2) +
geom_smooth(aes(color = "Trend Line"), method = "lm", linewidth = 1, se = TRUE) +
labs(title = "Relationship between Feedback Scores and Mean Assessment Weight",
x = "feedback scores(overall_score)",
y = "Mean Assessment Weight",
color = "Legend") +
scale_color_manual(values = c("Weight" = "red", "Trend Line" = "blue"),
labels = c("Trend Line", "Assessment Weight")) +
theme_minimal()
# Merge the "code_module" and "code_presentation" columns from assessments.csv into studentAssessment.csv
merged_student_assessment <- student_assessment %>%
inner_join(assessments %>% select(id_assessment, code_module, code_presentation), by = "id_assessment")
# Print id_assessment, code_module, and code_presentation columns
print(merged_student_assessment %>% select(id_assessment, code_module, code_presentation))
# Generate the 'date_submitted' column from the 'dates_since_submitted' column
merged_student_assessment <- merged_student_assessment %>%
mutate(date_submitted = as.Date("2014-01-01") + days(dates_since_submitted))
# Print dates_since_submitted and date_submitted columns
print(merged_student_assessment %>% select(id_assessment, dates_since_submitted, date_submitted))
# Check the range of 'dates_since_submitted' and 'date_submitted' columns
dates_range_values <- merged_student_assessment %>%
summarise(
min_dates_since_submitted = min(dates_since_submitted),
max_dates_since_submitted = max(dates_since_submitted),
min_date_submitted = min(date_submitted),
max_date_submitted = max(date_submitted)
)
# Print the range values
glimpse(dates_range_values)
# Filter out rows where the score column is NA
score_na_df <- merged_student_assessment %>%
filter(is.na(score))
# Print the first 5 rows of the data
print(head(score_na_df %>% select(id_assessment, score, date_submitted), 5))
# Check for NA values in the score column
# Filter out rows where the score column is not NA
merged_student_assessment_filtered <- merged_student_assessment %>%
filter(!is.na(score))
# Check the range of the score column
scores_range_values <- merged_student_assessment_filtered %>%
summarise(min_score = min(score), max_score = max(score))
# Print the range values
print(scores_range_values)
# Draw a chart to show student average scores against the date submitted
average_scores_date <- merged_student_assessment %>%
group_by(date_submitted) %>%
summarise(average_score = mean(score, na.rm = TRUE))
# Visualize student average scores against the date submitted
ggplot(average_scores_date, aes(x = date_submitted, y = average_score)) +
geom_line() +
labs(title = "Student Average Scores Against Date Submitted",
x = "Date Submitted",
y = "Average Score") +
theme_minimal()
# Filter the assessment data relevant to students from the code_module of AAA and code_presentation of 2013J
AAA_2013J_df <- merged_student_assessment %>%
filter(code_module == "AAA" & code_presentation == "2013J")
# Print the first 5 rows of the filtered data
print(AAA_2013J_df %>% select(id_assessment, code_module, code_presentation))
# Check for NA values in the score column
AAA_2013J_df_score_na <- AAA_2013J_df %>%
filter(is.na(score))
# Print the NA values in the score column
print(AAA_2013J_df_score_na)
# Fill in NA values in the 'score' column with the mean of the score column
AAA_2013J_df <- AAA_2013J_df %>%
mutate(score = ifelse(is.na(score), mean(score, na.rm = TRUE), score))
# Check for NA values in the score column
na_values_score <- AAA_2013J_df %>%
summarise(score_na = sum(is.na(score)))
# Print the NA values in the score column
print(na_values_score)
# Check the range of the score in score column and categorize them into the 4 score ranges and store in a new column "score_range"
AAA_2013J_df <- AAA_2013J_df %>%
mutate(score_range = case_when(
score >= 0 & score < 60 ~ "[0, 60)",
score >= 60 & score < 70 ~ "[60, 70)",
score >= 70 & score < 80 ~ "[70, 80)",
score >= 80 & score <= 100 ~ "[80, 100]"
))
# Print the first 5 rows of the data with the new "score_range" column
print(head(AAA_2013J_df %>% select(id_assessment, score, score_range), 5))
# Plot the number of students of different `score_range` values for each `id_assessment` using a bar chart.
score_range_plot <- AAA_2013J_df %>%
group_by(id_assessment, score_range) %>%
summarise(count = n(), .groups = 'drop') %>%
ggplot(aes(x = id_assessment, y = count, fill = score_range)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Number of Students of Different Score Range for Each id_assessment",
x = "id_assessment",
y = "Number of Students",
fill = "Score Range") +
theme_minimal() +
scale_fill_brewer(palette = "Set1")
# Print the plot
print(score_range_plot)
# Check for NA values in the is_banked column
na_values_is_banked <- student_assessment %>%
summarise(is_banked_na = sum(is.na(is_banked)))
# Print the NA values in the is_banked column
print(na_values_is_banked)
# Filter out rows where the score column is not NA
student_assessment_removed_score_na <- student_assessment %>%
filter(!is.na(score))
# Plot a comparison of scores between banked and non-banked assessments
ggplot(student_assessment_removed_score_na, aes(x = as.factor(is_banked), y = score, fill = as.factor(is_banked))) +
geom_boxplot() +
labs(title = "Comparison of Scores: Banked vs Non-Banked Assessments",
x = "Is Banked",
y = "Score",
fill = "Is Banked") +
scale_fill_discrete(labels = c("No", "Yes")) +
theme_minimal()
# Merge the "assessment_type" column from assessments.csv into studentAssessment
student_assessment_with_type <- student_assessment %>%
inner_join(assessments %>% select(id_assessment, assessment_type), by = "id_assessment")
# Print the first 5 rows of the merged data
print(student_assessment_with_type %>% select(id_assessment, score, assessment_type))
# Investigate the relationship between the score, assessment_type, and is_banked
# Calculate the average score for each assessment type, is_banked combination
avg_scores_assessment_type <- student_assessment_with_type %>%
group_by(assessment_type, is_banked) %>%
summarise(avg_score = mean(score, na.rm = TRUE), count_students = n())
# Print summary of average scores for each assessment type, is_banked combination
print(avg_scores_assessment_type)
# Visualize the relationship between the score, assessment_type, and is_banked
ggplot(student_assessment_with_type, aes(x = assessment_type, y = score, fill = as.factor(is_banked))) +
geom_boxplot() +
labs(title = "Comparison of Scores: Assessment Type and Is Banked",
x = "Assessment Type",
y = "Score",
fill = "Is Banked") +
scale_fill_discrete(labels = c("No", "Yes")) +
theme_minimal()
# Calculate the frequency of each student in the dataset
student_frequency <- student_assessment %>%
count(id_student, name = "frequency") %>%
arrange(desc(frequency))
# Print the top 10 students with the highest frequency
print(head(student_frequency, 10))
# Filter out data of the top 3 students that appear most frequently in the dataset
top_3_students <- student_assessment %>%
filter(id_student %in% head(student_frequency$id_student, 3))
# Print the first 5 rows of the data for the top 3 students
print(top_3_students)
# Get some statistics of the 3 students' performance
performance_stats <- top_3_students %>%
group_by(id_student) %>%
summarise(
mean_score = mean(score, na.rm = TRUE),
min_score = min(score, na.rm = TRUE),
max_score = max(score, na.rm = TRUE)
)
# Print the performance statistics of the top 3 students
print(performance_stats)
# Analyze relationship between submission timing and performance
ggplot(top_3_students, aes(x = dates_since_submitted, y = score, color = factor(id_student))) +
geom_point() +
facet_wrap(~ id_student, ncol = 1) +
scale_color_manual(values = c("red", "blue", "black")) +
labs(title = "Submission Timing vs Performance",
x = "Days Since Submitted",
y = "Score",
color = "Student ID") +
theme_minimal()
install.packages('IRkernel')
IRkernel::installspec()
IRkernel::installspec()
install.packages('IRkernel')
IRkernel::installspec()
install.packages("readxl")
setwd("D:/R-Studio/FDS/FDS_A3")
# Read Excel File
library(knitr)
library(ggplot2)
library(tidyverse)
library(naniar)
library(reshape2)
library(caret)
library(readxl)
file_path = "Claims-statistical-report-calendar-year-2024-06.xlsx"
# List all sheets in the Excel file
sheet_names <- excel_sheets(file_path)
print(sheet_names)
# Read Bodily location sheet
bodily_location <- read_excel(file_path, sheet = "Bodily location", skip = 3)
colnames(bodily_location)
bodily_location <- bodily_location[, 1:14]
# Rename columns to proper names (as shown in the screenshot)
colnames(bodily_location) <- c("Bodily Location", "2011", "2012", "2013",
"2014", "2015", "2016", "2017", "2018", "2019",
"2020", "2021", "2022", "2023")
# Drop any rows with all NA values
bodily_location <- bodily_location[complete.cases(bodily_location), ]
bodily_location
# Filter the row for "Eye" injuries
eye_injury_data <- bodily_location[bodily_location$`Bodily Location` == "12 Eye", ]
# Convert the year columns into numeric values for plotting
years <- as.numeric(colnames(eye_injury_data)[2:14])
eye_injuries <- as.numeric(eye_injury_data[1, 2:14])
# Plotting the data
plot(years, eye_injuries, type = "b", col = "blue", lwd = 2,
xlab = "Year", ylab = "Number of Eye Injuries",
main = "Eye Injuries from 2011 to 2023",
pch = 16)
# Adding grid lines for better readability
grid()
